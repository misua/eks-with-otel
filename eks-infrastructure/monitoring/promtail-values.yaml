# Promtail Configuration for Kubernetes Log Collection
# Collects logs from all pods and nodes, sends to Loki

# Promtail configuration
config:
  # Promtail server configuration
  server:
    http_listen_port: 3101
    grpc_listen_port: 9095
    log_level: info
    
  # Positions file to track log reading progress
  positions:
    filename: /tmp/positions.yaml
    
  # Loki client configuration
  clients:
    - url: http://loki-gateway.monitoring.svc.cluster.local/loki/api/v1/push
      tenant_id: ""
      
  # Scrape configurations for different log sources
  scrape_configs:
    # Kubernetes pod logs
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
        - role: pod
      pipeline_stages:
        - cri: {}
        - regex:
            expression: '^(?P<time>\S+) (?P<stream>stdout|stderr) (?P<flags>\S+) (?P<content>.*)$'
        - timestamp:
            source: time
            format: RFC3339Nano
        - output:
            source: content
      relabel_configs:
        # Only scrape pods that are running
        - source_labels: [__meta_kubernetes_pod_phase]
          action: keep
          regex: Running
        # Add namespace label
        - source_labels: [__meta_kubernetes_pod_namespace]
          target_label: namespace
        # Add pod name label
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod
        # Add container name label
        - source_labels: [__meta_kubernetes_pod_container_name]
          target_label: container
        # Add app label if exists
        - source_labels: [__meta_kubernetes_pod_label_app]
          target_label: app
        # Add service label if exists
        - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
          target_label: service
        # Set log path
        - source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
          target_label: __path__
          separator: /
          replacement: /var/log/pods/*$1/*.log
        # Drop logs from certain namespaces if needed
        - source_labels: [__meta_kubernetes_pod_namespace]
          action: drop
          regex: kube-system|kube-public
          
    # Kubernetes node logs (systemd journal)
    - job_name: kubernetes-nodes
      kubernetes_sd_configs:
        - role: node
      pipeline_stages:
        - json:
            expressions:
              message: MESSAGE
              timestamp: __REALTIME_TIMESTAMP
        - timestamp:
            source: timestamp
            format: Unix
        - output:
            source: message
      relabel_configs:
        # Add node name label
        - source_labels: [__meta_kubernetes_node_name]
          target_label: node
        # Set journal path
        - target_label: __path__
          replacement: /var/log/journal
        # Add job label
        - target_label: job
          replacement: kubernetes-nodes

# Deployment configuration
daemonset:
  enabled: true
  
# Service account configuration
serviceAccount:
  create: true
  name: promtail

# RBAC configuration
rbac:
  create: true
  pspEnabled: false

# Pod security context
podSecurityContext:
  runAsUser: 0
  runAsGroup: 0
  fsGroup: 0

# Container security context
containerSecurityContext:
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL
  allowPrivilegeEscalation: false

# Resources
resources:
  limits:
    cpu: 200m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Node selector (optional)
nodeSelector: {}

# Tolerations to run on all nodes
tolerations:
  - effect: NoSchedule
    operator: Exists
  - effect: NoExecute
    operator: Exists

# Volume mounts for log access
extraVolumes:
  - name: varlog
    hostPath:
      path: /var/log

extraVolumeMounts:
  - name: varlog
    mountPath: /var/log
    readOnly: true

# Service monitor for Prometheus
serviceMonitor:
  enabled: true
  namespace: monitoring
  labels:
    app: promtail

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "3101"
  prometheus.io/path: "/metrics"

# Update strategy
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1
